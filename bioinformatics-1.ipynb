{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12981341,"sourceType":"datasetVersion","datasetId":8216515}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install Bio Levenshtein -q","metadata":{"_uuid":"264cb42e-f0f4-4494-9c9c-e8791f730756","_cell_guid":"52a59bdd-8325-4d69-91af-47a51709eb4c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-19T08:39:28.079545Z","iopub.execute_input":"2025-09-19T08:39:28.079838Z","iopub.status.idle":"2025-09-19T08:39:39.351846Z","shell.execute_reply.started":"2025-09-19T08:39:28.079815Z","shell.execute_reply":"2025-09-19T08:39:39.349853Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from Bio import SeqIO\nimport numpy as np\nfrom gensim.models import FastText\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import normalize\nfrom scipy.stats import spearmanr, pearsonr\nfrom collections import defaultdict, Counter\nfrom typing import Callable, List, Tuple\nimport pandas as pd","metadata":{"_uuid":"49ed773c-5e88-4a74-87a3-d4f9ad2b18d3","_cell_guid":"80dcb0b1-8b42-4e21-85a7-4a66a918932a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-19T08:39:39.353310Z","iopub.execute_input":"2025-09-19T08:39:39.353584Z","iopub.status.idle":"2025-09-19T08:40:21.814487Z","shell.execute_reply.started":"2025-09-19T08:39:39.353556Z","shell.execute_reply":"2025-09-19T08:40:21.813342Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def evaluate_similarity_method(\n    file_path: str,\n    fitted_model: object,\n    method_name: str = \"Custom Method\",\n    max_sequences: int = 1000\n) -> dict:\n\n    sequences = []\n    sequence_ids = []\n\n    with open(file_path, \"r\") as handle:\n        for record in SeqIO.parse(handle, \"fasta\"):\n            seq = str(record.seq).strip()\n            if len(seq) > 10:\n                sequences.append(seq)\n                sequence_ids.append(record.id)\n\n    print(f\"Loaded {len(sequences)} sequences\")\n\n    sequences_subset = sequences[:max_sequences]\n    sequence_ids_subset = sequence_ids[:max_sequences]\n\n    if len(sequences_subset) == 0:\n        print(\"No sequences to process after filtering.\")\n        return {}\n\n    print(f\"Using {len(sequences_subset)} sequences for analysis\")\n\n    print(f\"Calculating similarities using {method_name}...\")\n    try:\n        similarities = fitted_model.predict(sequences_subset[0], sequences_subset)\n    except Exception as e:\n        print(f\"Error during prediction with {method_name}: {e}\")\n        return {}\n\n    print(f\"\\nFinding sequences most similar to the first one using {method_name}:\")\n    print(f\"First sequence ID: {sequence_ids_subset[0]}\")\n    print(f\"First sequence length: {len(sequences_subset[0])} amino acids\")\n\n    similarity_results = []\n    for i in range(len(sequences_subset)):\n        similarity_results.append((\n            i,\n            similarities[i],\n            sequence_ids_subset[i],\n            sequences_subset[i][:50]\n        ))\n\n    similarity_results.sort(key=lambda x: x[1], reverse=True)\n\n    print(f\"\\nTop 10 most similar sequences to {sequence_ids_subset[0]}:\")\n    print(\"-\" * 80)\n    for i, (idx, sim, seq_id, seq_preview) in enumerate(similarity_results[:10]):\n        print(f\"{i+1:2d}. Similarity: {sim:.4f} | ID: {seq_id}\")\n        print(f\"    Sequence: {seq_preview}...\")\n        print()\n\n    print(\"=\"*50)\n    print(f\"METRICS FOR {method_name.upper()}\")\n    print(\"=\"*50)\n\n    ground_truth_ranks = list(range(len(sequences_subset)))\n\n    predicted_similarities = similarities\n    predicted_ranks = np.argsort(np.argsort(-predicted_similarities))\n\n    if len(ground_truth_ranks) > 1 and len(np.unique(predicted_ranks)) > 1:\n        spearman_corr, spearman_p = spearmanr(ground_truth_ranks, predicted_ranks)\n        pearson_corr, pearson_p = pearsonr(ground_truth_ranks, predicted_ranks)\n    else:\n        spearman_corr = pearson_corr = 0.0\n        spearman_p = pearson_p = 1.0\n\n    print(f\"Spearman correlation: {spearman_corr:.4f} (p-value: {spearman_p:.4f})\")\n    print(f\"Pearson correlation: {pearson_corr:.4f} (p-value: {pearson_p:.4f})\")\n\n    def calculate_ndcg(ground_truth_ranks, predicted_ranks, k=10):\n        if len(ground_truth_ranks) == 0:\n            return 0.0\n        ideal_ranking = list(range(len(ground_truth_ranks)))\n\n        top_k_predicted = np.argsort(predicted_ranks)[:min(k, len(predicted_ranks))]\n        top_k_ideal = ideal_ranking[:min(k, len(ideal_ranking))]\n\n        dcg = 0\n        for i, idx in enumerate(top_k_predicted):\n            rel = 1.0 / (ground_truth_ranks[idx] + 1) if ground_truth_ranks[idx] > 0 else 1.0\n            dcg += rel / np.log2(i + 2)\n\n        idcg = 0\n        for i in range(len(top_k_ideal)):\n            rel = 1.0 / (ideal_ranking[i] + 1) if ideal_ranking[i] > 0 else 1.0\n            idcg += rel / np.log2(i + 2)\n\n        return dcg / idcg if idcg > 0 else 0\n\n    ndcg_10 = calculate_ndcg(ground_truth_ranks, predicted_ranks, k=10)\n    ndcg_all = calculate_ndcg(ground_truth_ranks, predicted_ranks, k=len(sequences_subset))\n\n    print(f\"NDCG@10: {ndcg_10:.4f}\")\n    print(f\"NDCG@all: {ndcg_all:.4f}\")\n\n    from scipy.stats import kendalltau\n    if len(ground_truth_ranks) > 1:\n        tau, tau_p = kendalltau(ground_truth_ranks, predicted_ranks)\n    else:\n        tau, tau_p = 0.0, 1.0\n    print(f\"Kendall's Tau: {tau:.4f} (p-value: {tau_p:.4f})\")\n\n    print(f\"\\nSummary for {method_name}:\")\n    print(\"-\" * 40)\n    print(f\"Total sequences processed: {len(sequences_subset)}\")\n    print(f\"Ground truth correlation (Spearman): {spearman_corr:.4f}\")\n    print(f\"Ranking quality (NDCG@10): {ndcg_10:.4f}\")\n    print(f\"Kendall's Tau: {tau:.4f}\")\n\n    return {\n        'method': method_name,\n        'sequences_processed': len(sequences_subset),\n        'spearman_correlation': spearman_corr,\n        'pearson_correlation': pearson_corr,\n        'ndcg_10': ndcg_10,\n        'ndcg_all': ndcg_all,\n        'kendall_tau': tau,\n        'spearman_p_value': spearman_p,\n        'pearson_p_value': pearson_p,\n        'kendall_tau_p_value': tau_p\n    }","metadata":{"_uuid":"8a3533f5-5e02-4e51-a4dc-e89e5b279f6f","_cell_guid":"f823bffd-e056-4d3b-8ee9-7f557f7979d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-19T08:40:21.817121Z","iopub.execute_input":"2025-09-19T08:40:21.817705Z","iopub.status.idle":"2025-09-19T08:40:21.838878Z","shell.execute_reply.started":"2025-09-19T08:40:21.817676Z","shell.execute_reply":"2025-09-19T08:40:21.837116Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class LevenshteinSimilarityModel:\n    def __init__(self):\n        from Levenshtein import distance as levenshtein_distance\n        self._levenshtein_distance = levenshtein_distance\n\n    def predict(self, query_sequence: str, sequences: List[str]) -> np.ndarray:\n        similarities = []\n        for seq in sequences:\n            dist = self._levenshtein_distance(query_sequence, seq)\n            max_len = max(len(query_sequence), len(seq))\n            if max_len > 0:\n                similarity = 1 - (dist / max_len)\n            else:\n                similarity = 1.0\n            similarities.append(similarity)\n        return np.array(similarities)\n\n    def find_closest_in_fitted_set(self, query_sequence: str, fitted_sequences: List[str]) -> Tuple[str, float]:\n        if not fitted_sequences:\n            return \"\", 0.0\n        distances = [self._levenshtein_distance(query_sequence, seq) for seq in fitted_sequences]\n        min_idx = np.argmin(distances)\n        min_dist = distances[min_idx]\n        max_len = max(len(query_sequence), len(fitted_sequences[min_idx]))\n        similarity = 1 - (min_dist / max_len) if max_len > 0 else 1.0\n        return fitted_sequences[min_idx], similarity","metadata":{"_uuid":"e67e78b5-3e24-4aaa-9d32-505d5fab08f3","_cell_guid":"15382cec-04b4-4dd8-b3af-7bbfce8435c4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-19T08:40:21.839837Z","iopub.execute_input":"2025-09-19T08:40:21.840351Z","iopub.status.idle":"2025-09-19T08:40:21.883786Z","shell.execute_reply.started":"2025-09-19T08:40:21.840318Z","shell.execute_reply":"2025-09-19T08:40:21.882677Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class LengthSimilarityModel:\n    def __init__(self):\n        pass\n\n    def predict(self, query_sequence: str, sequences: List[str]) -> np.ndarray:\n        query_seq_len = len(query_sequence)\n        similarities = []\n        for seq in sequences:\n            seq_len = len(seq)\n            max_len = max(query_seq_len, seq_len)\n            if max_len > 0:\n                length_diff = abs(query_seq_len - seq_len)\n                normalized_diff = length_diff / max_len\n                similarity = 1 - normalized_diff\n            else:\n                similarity = 1.0\n            similarities.append(similarity)\n        return np.array(similarities)\n\n    def find_closest_in_fitted_set(self, query_sequence: str, fitted_sequences: List[str]) -> Tuple[str, float]:\n        if not fitted_sequences:\n            return \"\", 0.0\n        query_len = len(query_sequence)\n        lengths = [len(seq) for seq in fitted_sequences]\n        diffs = [abs(query_len - l) for l in lengths]\n        min_idx = np.argmin(diffs)\n        min_diff = diffs[min_idx]\n        max_len = max(query_len, lengths[min_idx])\n        similarity = 1 - (min_diff / max_len) if max_len > 0 else 1.0\n        return fitted_sequences[min_idx], similarity","metadata":{"_uuid":"f5bc73f6-2bc9-40c7-afb0-f310077146b0","_cell_guid":"4c600063-5de9-48b6-98cf-45d40a4fc90f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-19T08:40:21.884927Z","iopub.execute_input":"2025-09-19T08:40:21.885215Z","iopub.status.idle":"2025-09-19T08:40:21.916210Z","shell.execute_reply.started":"2025-09-19T08:40:21.885192Z","shell.execute_reply":"2025-09-19T08:40:21.915052Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ExactMatchSimilarityModel:\n    def __init__(self):\n        pass\n\n    def predict(self, query_sequence: str, sequences: List[str]) -> np.ndarray:\n        similarities = []\n        for seq in sequences:\n            if seq == query_sequence:\n                similarity = 1.0\n            else:\n                similarity = 0.0\n            similarities.append(similarity)\n        return np.array(similarities)\n\n    def find_closest_in_fitted_set(self, query_sequence: str, fitted_sequences: List[str]) -> Tuple[str, float]:\n        for seq in fitted_sequences:\n            if seq == query_sequence:\n                return seq, 1.0\n        return \"\", 0.0","metadata":{"_uuid":"a4b4149a-a75e-475b-8c5e-d7642798543e","_cell_guid":"94dca7f6-e6e3-428e-93aa-c9e7aa3a00cc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-19T08:40:21.917411Z","iopub.execute_input":"2025-09-19T08:40:21.917773Z","iopub.status.idle":"2025-09-19T08:40:21.945594Z","shell.execute_reply.started":"2025-09-19T08:40:21.917743Z","shell.execute_reply":"2025-09-19T08:40:21.944342Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PreFittedGensimFastTextSimilarityModel:\n    def __init__(self, k: int = 3, vector_size: int = 100, window: int = 5,\n                 min_count: int = 2, epochs: int = 10, workers: int = 4):\n        self.k = k\n        self.vector_size = vector_size\n        self.window = window\n        self.min_count = min_count\n        self.epochs = epochs\n        self.workers = workers\n        self.model = None\n        self.fitted = False\n        self._fitted_sequences = []\n\n    def _sequence_to_kmers_list(self, sequence):\n        if len(sequence) < self.k:\n            return [sequence]\n        return [sequence[i:i+self.k] for i in range(len(sequence)-self.k+1)]\n\n    def fit(self, sequences: List[str]):\n        self._fitted_sequences = sequences[:]\n        kmers_sequences = [self._sequence_to_kmers_list(seq) for seq in sequences]\n\n        self.model = FastText(\n            sentences=kmers_sequences,\n            vector_size=self.vector_size,\n            window=self.window,\n            min_count=self.min_count,\n            workers=self.workers,\n            epochs=self.epochs,\n            sg=1\n        )\n        self.fitted = True\n\n    def _get_sequence_vector(self, sequence):\n        kmers = self._sequence_to_kmers_list(sequence)\n        vectors = []\n        for kmer in kmers:\n            try:\n                vectors.append(self.model.wv[kmer])\n            except KeyError:\n                try:\n                    vec = self.model.wv.word_vec(kmer, use_norm=True)\n                    vectors.append(vec)\n                except KeyError:\n                    continue\n\n        if vectors:\n            return np.mean(vectors, axis=0)\n        else:\n            return np.zeros(self.model.vector_size)\n\n    def predict(self, query_sequence: str, sequences: List[str]) -> np.ndarray:\n        if not self.fitted or self.model is None:\n            raise ValueError(\"Model must be fitted before predict.\")\n\n        query_vector = self._get_sequence_vector(query_sequence).reshape(1, -1)\n        sequence_vectors = np.array([self._get_sequence_vector(seq) for seq in sequences])\n        similarities = cosine_similarity(query_vector, sequence_vectors)[0]\n        return similarities\n\n    def find_closest_in_fitted_set(self, query_sequence: str, fitted_sequences: List[str] = None) -> Tuple[str, float]:\n        if fitted_sequences is None:\n            fitted_sequences = self._fitted_sequences\n        if not fitted_sequences or not self.fitted:\n            return \"\", 0.0\n\n        query_vector = self._get_sequence_vector(query_sequence).reshape(1, -1)\n        fitted_vectors = np.array([self._get_sequence_vector(seq) for seq in fitted_sequences])\n        similarities = cosine_similarity(query_vector, fitted_vectors)[0]\n        max_idx = np.argmax(similarities)\n        return fitted_sequences[max_idx], similarities[max_idx]","metadata":{"_uuid":"77a3e2da-c7b8-40f5-afc6-c0f52eafb2bc","_cell_guid":"2da77d5e-3cc7-4989-a3dd-fc8f0b88a032","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-19T08:40:21.946722Z","iopub.execute_input":"2025-09-19T08:40:21.947061Z","iopub.status.idle":"2025-09-19T08:40:21.973510Z","shell.execute_reply.started":"2025-09-19T08:40:21.947037Z","shell.execute_reply":"2025-09-19T08:40:21.972420Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class PreFittedKmerTfidfSimilarityModel:\n    def __init__(self, k: int = 3, min_freq: int = 2):\n        self.k = k\n        self.min_freq = min_freq\n        self.vectorizer = None\n        self.fitted = False\n        self._fitted_vocab = None\n        self._fitted_sequences = []\n\n    def _generate_kmers(self, sequence):\n        return [sequence[i:i+self.k] for i in range(len(sequence) - self.k + 1)]\n\n    def fit(self, sequences: List[str]):\n        self._fitted_sequences = sequences[:]\n        processed_sequences = []\n        for seq in sequences:\n            kmers = self._generate_kmers(seq)\n            processed_sequences.append(' '.join(kmers))\n\n        self.vectorizer = TfidfVectorizer(\n            tokenizer=lambda x: x.split(),\n            lowercase=False,\n            token_pattern=None,\n            min_df=self.min_freq,\n            ngram_range=(1, 1)\n        )\n\n        _ = self.vectorizer.fit_transform(processed_sequences)\n        self.fitted = True\n        self._fitted_vocab = set(self.vectorizer.vocabulary_.keys())\n\n    def predict(self, query_sequence: str, sequences: List[str]) -> np.ndarray:\n        if not self.fitted or self.vectorizer is None:\n            raise ValueError(\"Model must be fitted before predict.\")\n\n        query_kmers = self._generate_kmers(query_sequence)\n        processed_query = ' '.join(query_kmers)\n        query_vector = self.vectorizer.transform([processed_query])\n\n        processed_sequences = []\n        for seq in sequences:\n            kmers = self._generate_kmers(seq)\n            processed_sequences.append(' '.join(kmers))\n        \n        sequences_vectors = self.vectorizer.transform(processed_sequences)\n        similarities = cosine_similarity(query_vector, sequences_vectors)[0]\n        return similarities\n\n    def find_closest_in_fitted_set(self, query_sequence: str, fitted_sequences: List[str] = None) -> Tuple[str, float]:\n        if fitted_sequences is None:\n            fitted_sequences = self._fitted_sequences\n        if not fitted_sequences or not self.fitted:\n            return \"\", 0.0\n\n        query_kmers = self._generate_kmers(query_sequence)\n        processed_query = ' '.join(query_kmers)\n        query_vector = self.vectorizer.transform([processed_query])\n\n        processed_fitted = []\n        for seq in fitted_sequences:\n            kmers = self._generate_kmers(seq)\n            processed_fitted.append(' '.join(kmers))\n\n        fitted_vectors = self.vectorizer.transform(processed_fitted)\n        similarities = cosine_similarity(query_vector, fitted_vectors)[0]\n        max_idx = np.argmax(similarities)\n        return fitted_sequences[max_idx], similarities[max_idx]","metadata":{"_uuid":"407c6e8e-1814-495e-bdce-fe349e6fb3c0","_cell_guid":"2606a725-db9d-4db7-a9a8-bac87b636800","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-19T08:40:21.974741Z","iopub.execute_input":"2025-09-19T08:40:21.975080Z","iopub.status.idle":"2025-09-19T08:40:22.005877Z","shell.execute_reply.started":"2025-09-19T08:40:21.975048Z","shell.execute_reply":"2025-09-19T08:40:22.004786Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"file_path = \"/kaggle/input/uniprot-sprot/uniprot_sprot.fasta\"\n\nprint(\"Fitting models...\")\n\nfit_sequences = []\nwith open(file_path, \"r\") as handle:\n    for i, record in enumerate(SeqIO.parse(handle, \"fasta\")):\n        if i >= 5000:\n            break\n        seq = str(record.seq).strip()\n        if len(seq) > 10:\n            fit_sequences.append(seq)\n\ntfidf_model = PreFittedKmerTfidfSimilarityModel(k=3, min_freq=2)\ntfidf_model.fit(fit_sequences)\nprint(\"TF-IDF model fitted.\")\n\nfasttext_model = PreFittedGensimFastTextSimilarityModel(k=3, vector_size=50, epochs=5)\nfasttext_model.fit(fit_sequences)\nprint(\"FastText model fitted.\")\n\nmethods = [\n    (LevenshteinSimilarityModel(), \"Levenshtein Distance\"),\n    (LengthSimilarityModel(), \"Length-based\"),\n    (ExactMatchSimilarityModel(), \"Exact Match\"),\n    (tfidf_model, \"Pre-fitted TF-IDF (3-mers)\"),\n    (fasttext_model, \"Pre-fitted Gensim FastText (3-mers)\"),\n]\n\nresults = []\nfor fitted_model, method_name in methods:\n    try:\n        print(f\"\\n{'='*20} Evaluating {method_name} {'='*20}\")\n        max_seqs = 100 if \"Levenshtein\" in method_name else 1000\n\n        result = evaluate_similarity_method(\n            '/kaggle/input/uniprot-sprot/uniprot-choline_esterase_reviewed-yes.fasta',\n            fitted_model,\n            method_name,\n            max_sequences=max_seqs\n        )\n        if result:\n            results.append(result)\n        print(f\"Completed evaluation for {method_name}\\n\")\n    except Exception as e:\n        print(f\"Error evaluating {method_name}: {e}\")\n\nif results:\n    print(\"\\n\" + \"=\"*70)\n    print(\"COMPARISON OF ALL METHODS\")\n    print(\"=\"*70)\n\n    comparison_df = pd.DataFrame(results)\n    if not comparison_df.empty:\n        print_table = comparison_df[[\n            'method', 'sequences_processed', 'spearman_correlation',\n            'ndcg_10', 'kendall_tau'\n        ]].round(4)\n        print(print_table.to_string(index=False))\n    else:\n        print(\"No results to display.\")\nelse:\n    print(\"No methods were successfully evaluated.\")","metadata":{"_uuid":"fcb7a894-db77-403b-b344-4c1f8e8f9f1a","_cell_guid":"e5ee8dfc-c297-4fb2-82fe-c5b395831c16","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-19T08:40:22.008502Z","iopub.execute_input":"2025-09-19T08:40:22.008755Z","iopub.status.idle":"2025-09-19T08:41:21.320542Z","shell.execute_reply.started":"2025-09-19T08:40:22.008736Z","shell.execute_reply":"2025-09-19T08:41:21.319083Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Fitting models...\nTF-IDF model fitted.\nFastText model fitted.\n\n==================== Evaluating Levenshtein Distance ====================\nLoaded 69 sequences\nUsing 69 sequences for analysis\nCalculating similarities using Levenshtein Distance...\n\nFinding sequences most similar to the first one using Levenshtein Distance:\nFirst sequence ID: sp|P06276|CHLE_HUMAN\nFirst sequence length: 602 amino acids\n\nTop 10 most similar sequences to sp|P06276|CHLE_HUMAN:\n--------------------------------------------------------------------------------\n 1. Similarity: 1.0000 | ID: sp|P06276|CHLE_HUMAN\n    Sequence: MHSKVTIICIRFLFWFLLLCMLIGKSHTEDDIIIATKNGKVRGMNLTVFG...\n\n 2. Similarity: 0.8970 | ID: sp|P32749|CHLE_BOVIN\n    Sequence: MQSRSTVIYIRFVLWFLLLWVLFEKSHTEEDIIITTKNGKVRGMHLPVLG...\n\n 3. Similarity: 0.8887 | ID: sp|P21927|CHLE_RABIT\n    Sequence: MVTRSSHTEDVIITTKNGRIRGINLPVFGGTVTAFLGIPYAQPPLGRLRF...\n\n 4. Similarity: 0.8704 | ID: sp|O62760|CHLE_FELCA\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 5. Similarity: 0.8671 | ID: sp|O62761|CHLE_PANTT\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 6. Similarity: 0.8605 | ID: sp|P81908|CHLE_HORSE\n    Sequence: EEDIIITTKNGKVRGMNLPVLGGTVTAFLGIPYAQPPLGRLRFKKPQSLT...\n\n 7. Similarity: 0.7960 | ID: sp|Q03311|CHLE_MOUSE\n    Sequence: MQTQHTKVTQTHFLLWILLLCMPFGKSHTEEDFIITTKTGRVRGLSMPVL...\n\n 8. Similarity: 0.5245 | ID: sp|O42275|ACES_ELEEL\n    Sequence: MKILDALLFPVIFIMFFIHLSIAQTDPELTIMTRLGQVQGTRLPVPDRSH...\n\n 9. Similarity: 0.5221 | ID: sp|Q9DDE3|ACES_DANRE\n    Sequence: MKTSDILLLPTVLLTFLFHNCFAQAEPDLVVATRLGRVQGTRLPVPDRSH...\n\n10. Similarity: 0.5179 | ID: sp|P37136|ACES_RAT\n    Sequence: MRPPWYPLHTPSLASPLLFLLLSLLGGGARAEGREDPQLLVRVRGGQLRG...\n\n==================================================\nMETRICS FOR LEVENSHTEIN DISTANCE\n==================================================\nSpearman correlation: 0.2718 (p-value: 0.0239)\nPearson correlation: 0.2718 (p-value: 0.0239)\nNDCG@10: 0.8754\nNDCG@all: 0.9103\nKendall's Tau: 0.1782 (p-value: 0.0304)\n\nSummary for Levenshtein Distance:\n----------------------------------------\nTotal sequences processed: 69\nGround truth correlation (Spearman): 0.2718\nRanking quality (NDCG@10): 0.8754\nKendall's Tau: 0.1782\nCompleted evaluation for Levenshtein Distance\n\n\n==================== Evaluating Length-based ====================\nLoaded 69 sequences\nUsing 69 sequences for analysis\nCalculating similarities using Length-based...\n\nFinding sequences most similar to the first one using Length-based:\nFirst sequence ID: sp|P06276|CHLE_HUMAN\nFirst sequence length: 602 amino acids\n\nTop 10 most similar sequences to sp|P06276|CHLE_HUMAN:\n--------------------------------------------------------------------------------\n 1. Similarity: 1.0000 | ID: sp|P06276|CHLE_HUMAN\n    Sequence: MHSKVTIICIRFLFWFLLLCMLIGKSHTEDDIIIATKNGKVRGMNLTVFG...\n\n 2. Similarity: 1.0000 | ID: sp|P32749|CHLE_BOVIN\n    Sequence: MQSRSTVIYIRFVLWFLLLWVLFEKSHTEEDIIITTKNGKVRGMHLPVLG...\n\n 3. Similarity: 1.0000 | ID: sp|O62760|CHLE_FELCA\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 4. Similarity: 1.0000 | ID: sp|O62761|CHLE_PANTT\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 5. Similarity: 0.9983 | ID: sp|Q03311|CHLE_MOUSE\n    Sequence: MQTQHTKVTQTHFLLWILLLCMPFGKSHTEEDFIITTKTGRVRGLSMPVL...\n\n 6. Similarity: 0.9967 | ID: sp|Q9NDG8|ACE4_CAEBR\n    Sequence: MKPKLVFLPFLIFITVFIEESEAVHPVVLETKLGDIRGNEFFFLSKKIRT...\n\n 7. Similarity: 0.9934 | ID: sp|Q92035|ACES_BUNFA\n    Sequence: MPSCQPGKMPAPWPWWLQLLLCIPSCVAVLPGRAGELKVSTQTGSVRGLS...\n\n 8. Similarity: 0.9853 | ID: sp|O62763|ACES_FELCA\n    Sequence: MRPPWCPLYTPSLAAPILLLLLFLLGGGAEAEDPELLVTVRGGQLRGVRL...\n\n 9. Similarity: 0.9821 | ID: sp|P23795|ACES_BOVIN\n    Sequence: MRPPWCPLHTPSLTPPLLLLLFLIGGGAEAEGPEDPELLVMVRGGRLRGL...\n\n10. Similarity: 0.9805 | ID: sp|P37136|ACES_RAT\n    Sequence: MRPPWYPLHTPSLASPLLFLLLSLLGGGARAEGREDPQLLVRVRGGQLRG...\n\n==================================================\nMETRICS FOR LENGTH-BASED\n==================================================\nSpearman correlation: 0.1710 (p-value: 0.1602)\nPearson correlation: 0.1710 (p-value: 0.1602)\nNDCG@10: 0.7867\nNDCG@all: 0.8864\nKendall's Tau: 0.0827 (p-value: 0.3150)\n\nSummary for Length-based:\n----------------------------------------\nTotal sequences processed: 69\nGround truth correlation (Spearman): 0.1710\nRanking quality (NDCG@10): 0.7867\nKendall's Tau: 0.0827\nCompleted evaluation for Length-based\n\n\n==================== Evaluating Exact Match ====================\nLoaded 69 sequences\nUsing 69 sequences for analysis\nCalculating similarities using Exact Match...\n\nFinding sequences most similar to the first one using Exact Match:\nFirst sequence ID: sp|P06276|CHLE_HUMAN\nFirst sequence length: 602 amino acids\n\nTop 10 most similar sequences to sp|P06276|CHLE_HUMAN:\n--------------------------------------------------------------------------------\n 1. Similarity: 1.0000 | ID: sp|P06276|CHLE_HUMAN\n    Sequence: MHSKVTIICIRFLFWFLLLCMLIGKSHTEDDIIIATKNGKVRGMNLTVFG...\n\n 2. Similarity: 0.0000 | ID: sp|Q03311|CHLE_MOUSE\n    Sequence: MQTQHTKVTQTHFLLWILLLCMPFGKSHTEEDFIITTKTGRVRGLSMPVL...\n\n 3. Similarity: 0.0000 | ID: sp|P81908|CHLE_HORSE\n    Sequence: EEDIIITTKNGKVRGMNLPVLGGTVTAFLGIPYAQPPLGRLRFKKPQSLT...\n\n 4. Similarity: 0.0000 | ID: sp|Q04958|NTE1_YEAST\n    Sequence: MRSMNCTTNNTNNTGQNTKNSLGSSFNSSNYTSYRFQTCLTDQIISEAQT...\n\n 5. Similarity: 0.0000 | ID: sp|P21927|CHLE_RABIT\n    Sequence: MVTRSSHTEDVIITTKNGRIRGINLPVFGGTVTAFLGIPYAQPPLGRLRF...\n\n 6. Similarity: 0.0000 | ID: sp|P32749|CHLE_BOVIN\n    Sequence: MQSRSTVIYIRFVLWFLLLWVLFEKSHTEEDIIITTKNGKVRGMHLPVLG...\n\n 7. Similarity: 0.0000 | ID: sp|O62760|CHLE_FELCA\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 8. Similarity: 0.0000 | ID: sp|O62761|CHLE_PANTT\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 9. Similarity: 0.0000 | ID: sp|P32752|CHLE_PIG\n    Sequence: NTDQSFPGFVGSEMWNPNTELSEDCLYLNVWIPAPKPKNATVMIWIYGGG...\n\n10. Similarity: 0.0000 | ID: sp|P32750|CHLE_CANLF\n    Sequence: NTDQSFPGFPGSEMWNPNTDLSEDCLYLNVWIPTPKPKNATVMIWIYGGG...\n\n==================================================\nMETRICS FOR EXACT MATCH\n==================================================\nSpearman correlation: -0.4588 (p-value: 0.0001)\nPearson correlation: -0.4588 (p-value: 0.0001)\nNDCG@10: 0.5801\nNDCG@all: 0.7733\nKendall's Tau: -0.1824 (p-value: 0.0266)\n\nSummary for Exact Match:\n----------------------------------------\nTotal sequences processed: 69\nGround truth correlation (Spearman): -0.4588\nRanking quality (NDCG@10): 0.5801\nKendall's Tau: -0.1824\nCompleted evaluation for Exact Match\n\n\n==================== Evaluating Pre-fitted TF-IDF (3-mers) ====================\nLoaded 69 sequences\nUsing 69 sequences for analysis\nCalculating similarities using Pre-fitted TF-IDF (3-mers)...\n\nFinding sequences most similar to the first one using Pre-fitted TF-IDF (3-mers):\nFirst sequence ID: sp|P06276|CHLE_HUMAN\nFirst sequence length: 602 amino acids\n\nTop 10 most similar sequences to sp|P06276|CHLE_HUMAN:\n--------------------------------------------------------------------------------\n 1. Similarity: 1.0000 | ID: sp|P06276|CHLE_HUMAN\n    Sequence: MHSKVTIICIRFLFWFLLLCMLIGKSHTEDDIIIATKNGKVRGMNLTVFG...\n\n 2. Similarity: 0.7931 | ID: sp|P21927|CHLE_RABIT\n    Sequence: MVTRSSHTEDVIITTKNGRIRGINLPVFGGTVTAFLGIPYAQPPLGRLRF...\n\n 3. Similarity: 0.7654 | ID: sp|P32749|CHLE_BOVIN\n    Sequence: MQSRSTVIYIRFVLWFLLLWVLFEKSHTEEDIIITTKNGKVRGMHLPVLG...\n\n 4. Similarity: 0.7563 | ID: sp|P81908|CHLE_HORSE\n    Sequence: EEDIIITTKNGKVRGMNLPVLGGTVTAFLGIPYAQPPLGRLRFKKPQSLT...\n\n 5. Similarity: 0.7046 | ID: sp|O62760|CHLE_FELCA\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 6. Similarity: 0.6931 | ID: sp|O62761|CHLE_PANTT\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 7. Similarity: 0.5685 | ID: sp|Q03311|CHLE_MOUSE\n    Sequence: MQTQHTKVTQTHFLLWILLLCMPFGKSHTEEDFIITTKTGRVRGLSMPVL...\n\n 8. Similarity: 0.5021 | ID: sp|P32751|CHLE_MACMU\n    Sequence: NIDQSFPGFHGSEMWNPNTDLSEDCLYLNVWIPAPKPKNATVLIWIYGGG...\n\n 9. Similarity: 0.4544 | ID: sp|P32752|CHLE_PIG\n    Sequence: NTDQSFPGFVGSEMWNPNTELSEDCLYLNVWIPAPKPKNATVMIWIYGGG...\n\n10. Similarity: 0.4460 | ID: sp|P32753|CHLE_SHEEP\n    Sequence: NTDQSFPGFLGSEMWNPNTDLSEDCLYLNVWIPTPKPKNATVMIWIYGGS...\n\n==================================================\nMETRICS FOR PRE-FITTED TF-IDF (3-MERS)\n==================================================\nSpearman correlation: 0.3278 (p-value: 0.0060)\nPearson correlation: 0.3278 (p-value: 0.0060)\nNDCG@10: 0.9093\nNDCG@all: 0.9293\nKendall's Tau: 0.2208 (p-value: 0.0073)\n\nSummary for Pre-fitted TF-IDF (3-mers):\n----------------------------------------\nTotal sequences processed: 69\nGround truth correlation (Spearman): 0.3278\nRanking quality (NDCG@10): 0.9093\nKendall's Tau: 0.2208\nCompleted evaluation for Pre-fitted TF-IDF (3-mers)\n\n\n==================== Evaluating Pre-fitted Gensim FastText (3-mers) ====================\nLoaded 69 sequences\nUsing 69 sequences for analysis\nCalculating similarities using Pre-fitted Gensim FastText (3-mers)...\n\nFinding sequences most similar to the first one using Pre-fitted Gensim FastText (3-mers):\nFirst sequence ID: sp|P06276|CHLE_HUMAN\nFirst sequence length: 602 amino acids\n\nTop 10 most similar sequences to sp|P06276|CHLE_HUMAN:\n--------------------------------------------------------------------------------\n 1. Similarity: 1.0000 | ID: sp|P06276|CHLE_HUMAN\n    Sequence: MHSKVTIICIRFLFWFLLLCMLIGKSHTEDDIIIATKNGKVRGMNLTVFG...\n\n 2. Similarity: 0.9987 | ID: sp|P32749|CHLE_BOVIN\n    Sequence: MQSRSTVIYIRFVLWFLLLWVLFEKSHTEEDIIITTKNGKVRGMHLPVLG...\n\n 3. Similarity: 0.9987 | ID: sp|P21927|CHLE_RABIT\n    Sequence: MVTRSSHTEDVIITTKNGRIRGINLPVFGGTVTAFLGIPYAQPPLGRLRF...\n\n 4. Similarity: 0.9974 | ID: sp|O62761|CHLE_PANTT\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 5. Similarity: 0.9972 | ID: sp|O62760|CHLE_FELCA\n    Sequence: MQSKGTIISIQFLLRFLLLWVLIGKSHTEEDIIITTKNGKVRGMNLPVLD...\n\n 6. Similarity: 0.9970 | ID: sp|Q03311|CHLE_MOUSE\n    Sequence: MQTQHTKVTQTHFLLWILLLCMPFGKSHTEEDFIITTKTGRVRGLSMPVL...\n\n 7. Similarity: 0.9969 | ID: sp|P81908|CHLE_HORSE\n    Sequence: EEDIIITTKNGKVRGMNLPVLGGTVTAFLGIPYAQPPLGRLRFKKPQSLT...\n\n 8. Similarity: 0.9918 | ID: sp|Q27459|ACE1_CAEBR\n    Sequence: MRYSLLFFIFLPCVITAVDLIHLHDGSPLFGEEVLSQTGKPLTRFLGIPF...\n\n 9. Similarity: 0.9918 | ID: sp|P07692|ACES_TORMA\n    Sequence: MREMNLLVTSSLGVLLHLVVLCQADDDSELLVNTKSGKVMRTRIPVLSSH...\n\n10. Similarity: 0.9914 | ID: sp|Q9NDG8|ACE4_CAEBR\n    Sequence: MKPKLVFLPFLIFITVFIEESEAVHPVVLETKLGDIRGNEFFFLSKKIRT...\n\n==================================================\nMETRICS FOR PRE-FITTED GENSIM FASTTEXT (3-MERS)\n==================================================\nSpearman correlation: 0.3377 (p-value: 0.0045)\nPearson correlation: 0.3377 (p-value: 0.0045)\nNDCG@10: 0.8678\nNDCG@all: 0.9113\nKendall's Tau: 0.2413 (p-value: 0.0034)\n\nSummary for Pre-fitted Gensim FastText (3-mers):\n----------------------------------------\nTotal sequences processed: 69\nGround truth correlation (Spearman): 0.3377\nRanking quality (NDCG@10): 0.8678\nKendall's Tau: 0.2413\nCompleted evaluation for Pre-fitted Gensim FastText (3-mers)\n\n\n======================================================================\nCOMPARISON OF ALL METHODS\n======================================================================\n                             method  sequences_processed  spearman_correlation  ndcg_10  kendall_tau\n               Levenshtein Distance                   69                0.2718   0.8754       0.1782\n                       Length-based                   69                0.1710   0.7867       0.0827\n                        Exact Match                   69               -0.4588   0.5801      -0.1824\n         Pre-fitted TF-IDF (3-mers)                   69                0.3278   0.9093       0.2208\nPre-fitted Gensim FastText (3-mers)                   69                0.3377   0.8678       0.2413\n","output_type":"stream"}],"execution_count":9}]}